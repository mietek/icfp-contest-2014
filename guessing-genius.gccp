LDC 0          ; initial state
LDF @stepFunction
CONS
RTN
; ------------------------------------------------------------------------------
; @stepFunction
; arguments: AI State, World State
; returns: AI State, direction of next move
; ------------------------------------------------------------------------------
LDC 0          ; @stepFunction
LDC 3          ; start checking moves starting with 3
LDC 0          ; placeholder for best score
LDC 0          ; placeholder for current score
LDC 0          ; placholder for best move
LD 0 1         ; the world state
DUM 5
LDF @evaluateMoves
RAP 5          ; get best move
CONS           ; returning (state, direction)
RTN

; ------------------------------------------------------------------------------
; @evaluateMoves
; arguments: direction, *best score, *current score, *best move, world
; returns: direction
; ------------------------------------------------------------------------------
LD 0 0         ; current direction to check ; @evaluateMoves
LDC 5          ; iterations count for evaluateMove
LDC 0          ; accumulator for cumulative score of iterations
LD 0 4         ; pass the current world state
DUM 4
LDF @evaluateMove
RAP 4
ST 0 2         ; store current score for later
LD 0 2         ; load again to compare with
LD 0 1         ; the best one so far
CGT
SEL @gotBetterScore @gotWorseScore
LD 0 0
TSEL @checkNextMove @returnBestMove

LD 0 0         ; load current direction ; @checkNextMove
LDC -1
ADD            ; and subtract 1 to have the next one
LD 0 1         ; best score so far
LD 0 2         ; current score
LD 0 3         ; best move
LD 0 4         ; world
LDF @evaluateMoves
TAP 5          ; recursive call

LD 0 3         ; @returnBestMove
RTN

LD 0 2         ; @gotBetterScore
ST 0 1
LD 0 0
ST 0 3
JOIN           ; @gotWorseScore

; ------------------------------------------------------------------------------
; @evaluateMove
; arguments: direction, iterations count, *cumulative score, world
; returns: cumulative score
; ------------------------------------------------------------------------------
LD 0 1         ; iterations count ; @evaluateMove
TSEL @doAnotherIteration @returnCumulativeScore
LD 0 2         ; @returnCumulativeScore
RTN

LD 0 2         ; score so far ; @doAnotherIteration

LD 0 0         ; direction
LD 0 3         ; world
LDC 5          ; iterations count for single simulation
LDF @runSimulation
AP 3           ; get the resulting world

LDF @evaluateWorld
AP 1           ; get the new score

ADD            ; add it to the previous one
ST 0 2         ; and store for later
LD 0 0         ; preparing arguments for recursive call
LD 0 1
LDC -1         ; decrease the iterations count
ADD
LD 0 2
LD 0 3
LDF @evaluateMove
TAP 4

; ------------------------------------------------------------------------------
; @runSimulation
; arguments: direction, world, iteration
; returns: world
; ------------------------------------------------------------------------------
LD 0 0         ; @runSimulation
LD 0 1
LDC 0
LDC 0
LDC 0
LDC 0
LDF @simulateMove
AP 6           ; returns new world state
ST 0 1         ; store it for later
LD 0 2         ; @runSimulation
TSEL @doAnotherSimulationIteration @returnFinalWorld
LD 0 1         ; @returnFinalWorld
RTN
LD 0 0         ; @doAnotherSimulationIteration
LDF @generateNextRandomDirection
AP 1
LD 0 1         ; current world state
LD 0 2         ; iterations count
LDC -1         ; decreased by 1
ADD
LDF @runSimulation
TAP 3

; ------------------------------------------------------------------------------
; @generateNextRandomDirection
; arguments: direction
; returns: new direction
; ------------------------------------------------------------------------------
LD 0 0         ; @generateNextRandomDirection
RTN            ; to be implemented

; ------------------------------------------------------------------------------
; @simulateMove
; arguments: direction, world, empty, empty, empty, empty (padding for unpacked world)
; returns: new world
; ------------------------------------------------------------------------------
LD 0 1         ; @simulateMove
RTN            ; to be implemented

; ------------------------------------------------------------------------------
; @evaluateWorld
; arguments: world
; returns: score
; ------------------------------------------------------------------------------
LD 0 0         ; @evaluateWorld
CDR            ; player
CAR
CDR            ; player -> score
CDR
CDR
CDR
LDC 1          ; p1 - multiplier for score
MUL

LD 0 0
CDR            ; player
CAR
CDR            ; player -> lives
CDR
CDR
CAR
LDC 10000      ; p2 - multiplier for lives
MUL

LD 0 0
CDR            ; player
CAR
CAR            ; player -> vitality
LDC 0
CGT            ; we only want to know if fright mode is on
LDC 1000       ; p4 - multiplier for fright mode
MUL

ADD
ADD
RTN
; ------------------------------------------------------------------------------
